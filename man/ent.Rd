% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/ent.R
\name{ent}
\alias{ent}
\title{Entropy}
\usage{
ent(y, x, bins = NULL, na.rm = FALSE)
}
\arguments{
\item{y}{vector of observations}

\item{x}{matrix of samples of a predictive distribution (depending on \code{y}; see details)}

\item{bins}{numeric; if \code{NULL} the number of bins is equal to \code{ncol(x)+1}; otherwise \code{bins} must be chosen so that \code{(ncol(x)+1)/bins} is an integer; default: \code{NULL} (see details)}

\item{na.rm}{logical; if \code{TRUE} NA are stripped before the rank computation proceeds; if \code{FALSE} NA are used in the rank computation; default: \code{FALSE}}
}
\value{
Vector of the score value.
}
\description{
This function calculates the Entropy given observations of a univariate variable and samples of a predictive distribution.
}
\details{
For a vector \code{y} of length n, \code{x} should be given as matrix
with n rows, where the i-th entry of \code{y} belongs to the i-th row
of \code{x}. The columns of \code{x} represent the samples of a predictive distribution.

The parameter \code{bins} specifies the number of columns for the VRH. For "large"
\code{ncol(x)} it is often reasonable to reduce the resolution of the VRH by
using \code{bins} so that \code{(ncol(x)+1)/bins} is an integer.

The entropy is a tool to assess the calibration of a forecast. The optimal
value of the entropy is 1, representing a calibrated forecast.
}
\examples{
# simulated data
n <- 30
m <- 50
y <- rnorm(n)
x <- matrix(rnorm(n*m), ncol = m)

# entropy calculation
ent(y = y, x = x, bins = 3)

}
\references{
Tribus, M. (1969). Rational Descriptions, Decisions and Designs. Pergamon Press.
}
\author{
David Jobst
}
